# ğŸ§ª Gestos con CÃ¡mara Web: Control Visual con MediaPipe

## ğŸ“… Fecha
`2025_05_31`

---

## ğŸ¯ Objetivo del Taller

Usar la webcam y la biblioteca MediaPipe para detectar gestos de manos y ejecutar acciones visuales en tiempo real. El propÃ³sito es explorar cÃ³mo las interfaces naturales pueden usarse para interactuar con la pantalla de forma intuitiva, sin hardware adicional.

---

## ğŸ§  Conceptos Aprendidos

- [X] DetecciÃ³n de gestos con MediaPipe.
- [X] IntegraciÃ³n de gestos con aplicaciones visuales.
- [X] Uso de Python para procesamiento de imÃ¡genes y gestos.

---

## ğŸ”§ Herramientas y Entornos

- Python (`opencv-python`, `mediapipe`, `tkinter`, `threading`)

---

## ğŸ“ Estructura del Proyecto

```
2025_05_31_taller_gestos_webcam_mediapipe/
â”œâ”€â”€ python/                # Python
â”œâ”€â”€ resultados/            # capturas, mÃ©tricas, gifs
â”œâ”€â”€ README.md
```

---

## ğŸ§ª ImplementaciÃ³n


### ğŸ”¹ Etapas realizadas
1. InstalaciÃ³n de dependencias de Python.
2. ImplementaciÃ³n de un detector de gestos con MediaPipe.
3. IntegraciÃ³n de los gestos para controlar una aplicaciÃ³n visual.
4. GeneraciÃ³n de GIFs y documentaciÃ³n del proceso.


### ğŸ”¹ CÃ³digo relevante


#### Python

```python
def detectar_gestos():
    global estado_gesto
    mp_hands = mp.solutions.hands
    mp_dibujo = mp.solutions.drawing_utils
    hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
    cap = cv2.VideoCapture(0)

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        result = hands.process(rgb_frame)
```

```python
def detectar_gesto_mano(hand_landmarks, mp_hands):
    dedos = {
        "PULGAR": (mp_hands.HandLandmark.THUMB_TIP, mp_hands.HandLandmark.THUMB_IP),
        "INDICE": (mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.INDEX_FINGER_PIP),
        "MEDIO": (mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_PIP),
        "ANULAR": (mp_hands.HandLandmark.RING_FINGER_TIP, mp_hands.HandLandmark.RING_FINGER_PIP),
        "MENIQUE": (mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_PIP),
    }
    extendidos = {}
    for nombre, (tip, pip) in dedos.items():
        extendidos[nombre] = hand_landmarks.landmark[tip].y < hand_landmarks.landmark[pip].y
```


---
## ğŸ“Š Resultados Visuales



### Python
![Python](resultados/TestPython.gif)

---

## ğŸ§© Prompts Usados

### Python
```text
En un entorno Python como Colab, Jupyter Notebook o ejecuciÃ³n local, utiliza mediapipe, opencv-python y numpy para activar la cÃ¡mara web y capturar video en tiempo real. Emplea MediaPipe Hands para detectar gestos de mano y medir condiciones como el nÃºmero de dedos extendidos y la distancia entre dedos especÃ­ficos (por ejemplo, Ã­ndice y pulgar). A partir de estas seÃ±ales, implementa una escena visual interactiva donde se desencadenen acciones en respuesta a los gestos, tales como cambiar el color de fondo, mover un objeto en pantalla o cambiar de escena al detectar una palma abierta.
```

---

## ğŸ’¬ ReflexiÃ³n Final

- Â¿QuÃ© aprendiste o reforzaste con este taller?
AprendÃ­ a usar MediaPipe para la detecciÃ³n de gestos en tiempo real y cÃ³mo integrarlo con aplicaciones visuales en Python.
- Â¿QuÃ© parte fue mÃ¡s compleja o interesante?
La parte mÃ¡s interesante fue la integraciÃ³n de los gestos con acciones visuales, ya que permite una interacciÃ³n mÃ¡s natural y fluida con la computadora.
- Â¿QuÃ© mejorarÃ­as o quÃ© aplicarÃ­as en futuros proyectos?
MejorarÃ­a la precisiÃ³n de la detecciÃ³n de gestos y explorarÃ­a mÃ¡s acciones visuales que se puedan desencadenar con diferentes gestos.
---


## âœ… Checklist de Entrega

- [X] Carpeta `2025_05_31_taller_gestos_webcam_mediapipe`
- [X] CÃ³digo limpio y funcional
- [X] GIF incluido con nombre descriptivo
- [X] Visualizaciones o mÃ©tricas exportadas
- [X] README completo y claro
- [X] Commits descriptivos en inglÃ©s

---